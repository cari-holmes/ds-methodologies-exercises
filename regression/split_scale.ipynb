{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our scenario continues:\n",
    "\n",
    "As a customer analyst, I want to know who has spent the most money with us over their lifetime. \n",
    "I have monthly charges and tenure, so I think I will be able to use those two attributes as features to estimate total_charges. \n",
    "I need to do this within an average of $5.00 per customer.\n",
    "\n",
    "Create split_scale.py that will contain the functions that follow. \n",
    "Each scaler function should create the object, fit and transform both train and test. \n",
    "They should return the scaler, train dataframe scaled, test dataframe scaled. \n",
    "Be sure your indices represent the original indices from train/test, as those represent the indices from the original dataframe. \n",
    "Be sure to set a random state where applicable for reproducibility!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from wrangle import wrangle_telco\n",
    "import env \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, PowerTransformer, RobustScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull in my wrangle_telco() function and assign, drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   monthly_charges  tenure\n",
      "0           109.70      71\n",
      "1            84.65      63\n",
      "2            90.45      65\n",
      "3            45.20      54\n",
      "4           116.80      72\n",
      "   total_charges\n",
      "0        7904.25\n",
      "1        5377.80\n",
      "2        5957.90\n",
      "3        2460.55\n",
      "4        8456.75\n"
     ]
    }
   ],
   "source": [
    "df = wrangle_telco()\n",
    "X = df.drop(columns=['customer_id', 'total_charges'])\n",
    "y = pd.DataFrame(df['total_charges'])\n",
    "print(X.head()) \n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Methods\n",
    "Workflow:\n",
    "1. Create object \n",
    "2. Fit object\n",
    "3. Transform train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting my data frame into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_my_data(df, train_pct=.80, random_state=123):\n",
    "    train, test = train_test_split(df, train_size=train_pct, random_state=random_state)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a Standar Scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(train, test):\n",
    "    scaler = StandardScaler(copy=True, with_mean=True, with_std=True).fit(train)\n",
    "    train_scaled = pd.DataFrame(scaler.transform(train), columns=train.columns.values).set_index([train.index.values])\n",
    "    test_scaled = pd.DataFrame(scaler.transform(test), columns=test.columns.values).set_index([test.index.values])\n",
    "    return scaler, train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating an inverse function to return the scaled data back to its original verson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_inverse(scaler, train_scaler, test_scaler):\n",
    "    train_unscaled = pd.DataFrame(scaler.inverse_transform(train_scaled), columns=train_scaled.columns.values).set_index([train.index.values])\n",
    "    test_unscaled = pd.DataFrame(scaler.inverse_transform(test_scaled), columns=test_scaled.columns.values).set_index([test.index.values])\n",
    "    return scaler, train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a Uniform Scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_scaler(train, test):\n",
    "    scaler = QuantileTransformer(n_quantiles=100, output_distribution='uniform', random_state=123, copy=True).fit(train)\n",
    "    train_scaled = pd.DataFrame(scaler.transform(train), columns=train.columns.values).set_index([train.index.values])\n",
    "    test_scaled = pd.DataFrame(scaler.transform(test), columns=test.columns.values).set_index([test.index.values])\n",
    "    return scaler, train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a Gaussian Scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_scaler(train, test):\n",
    "    scaler = PowerTransformer(method='yeo-johnson', standardize=False, copy=True).fit(train)\n",
    "    train_scaled = pd.DataFrame(scaler.transform(train), columns=train.columns.values).set_index([train.index.values])\n",
    "    test_scaled = pd.DataFrame(scaler.transform(test), columns=test.columns.values).set_index([test.index.values])\n",
    "    return scaler, train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a MinMax Scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(train, test):\n",
    "    scaler = MinMaxScaler(copy=True, feature_range=(0,1)).fit(train)\n",
    "    train_scaled = pd.DataFrame(scaler.transform(train), columns=train.columns.values).set_index([train.index.values])\n",
    "    test_scaled = pd.DataFrame(scaler.transform(test), columns=test.columns.values).set_index([test.index.values])\n",
    "    return scaler, train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating an IQR Robust Scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_robust_scaler(train, test):\n",
    "    scaler = RobustScaler(quantile_range=(25.0,75.0), copy=True, with_centering=True, with_scaling=True).fit(train)\n",
    "    train_scaled = pd.DataFrame(scaler.transform(train), columns=train.columns.values).set_index([train.index.values])\n",
    "    test_scaled = pd.DataFrame(scaler.transform(test), columns=test.columns.values).set_index([test.index.values])\n",
    "    return scaler, train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the df into 4 data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_my_data(X, y, train_pct=.80):\n",
    "    X = df.drop(columns=['customer_id', 'total_charges'])\n",
    "    y = pd.DataFrame(df['total_charges'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=123)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standar Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_test, y_train, y_test):\n",
    "    scalerX = StandardScaler().fit(X_train)\n",
    "    scalery = StandardScaler().fit(y_train) \n",
    "    train_scaled_X = pd.DataFrame(scalerX.transform(X_train), columns=X_train.columns.values).set_index([X_train.index.values])\n",
    "    train_scaled_y = pd.DataFrame(scalery.transform(y_train), columns=y_train.columns.values).set_index([y_train.index.values])\n",
    "    test_scaled_X = pd.DataFrame(scalerX.transform(X_test), columns=X_test.columns.values).set_index([X_test.index.values])\n",
    "    test_scaled_y = pd.DataFrame(scalery.transform(y_test), columns=y_test.columns.values).set_index([y_test.index.values])\n",
    "    return scalerX, scalery, train_scaled_X, train_scaled_y, test_scaled_X, test_scaled_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_inverse(scalerX, scalery, train_scaled_X, train_scaled_y, test_scaled_X, test_scaled_y):\n",
    "    unscaledX = pd.DataFrame(scalerX.inverse_transform(train_scaled_X), columns=train_scaled_X.columns.values).set_index([X_train.index.values])\n",
    "    unscaledy = pd.DataFrame(scalery.inverse_transform(train_scaled_y), columns=train_scaled_y.columns.values).set_index([y_train.index.values])\n",
    "    test_X_unscaled = pd.DataFrame(scalerX.inverse_transform(test_scaled_X), columns=test_scaled_X.columns.values).set_index([X_test.index.values])\n",
    "    test_y_unscaled = pd.DataFrame(scalery.inverse_transform(test_scaled_y), columns=test_scaled_y.columns.values).set_index([y_test.index.values])\n",
    "    return unscaledX, unscaledy, test_X_unscaled, test_y_unscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniform Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_scaler(X_train, X_test, y_train, y_test):\n",
    "    scalerX = QuantileTransformer(n_quantiles=100, output_distribution='uniform', random_state=123, copy=True).fit(X_train)\n",
    "    scalery = QuantileTransformer(n_quantiles=100, output_distribution='uniform', random_state=123, copy=True).fit(y_train)\n",
    "    train_uniform_X = pd.DataFrame(scalerX.transform(X_train), columns=X_train.columns.values).set_index([X_train.index.values])\n",
    "    train_uniform_y = pd.DataFrame(scalery.transform(y_train), columns=y_train.columns.values).set_index([y_train.index.values])\n",
    "    test_uniform_X = pd.DataFrame(scalerX.transform(X_test), columns=X_test.columns.values).set_index([X_test.index.values])\n",
    "    test_uniform_y = pd.DataFrame(scalery.transform(y_test), columns=y_test.columns.values).set_index([y_test.index.values])\n",
    "    return scalerX, scalery, train_uniform_X, train_uniform_y, test_uniform_X, test_uniform_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_scaler(X_train, X_test, y_train, y_test):\n",
    "    scalerX = PowerTransformer(method='yeo-johnson', standardize=False, copy=True).fit(X_train)\n",
    "    scalery = PowerTransformer(method='yeo-johnson', standardize=False, copy=True).fit(y_train)\n",
    "    train_yeo_X = pd.DataFrame(scalerX.transform(X_train), columns=X_train.columns.values).set_index([X_train.index.values])\n",
    "    train_yeo_y = pd.DataFrame(scalery.transform(y_train), columns=y_train.columns.values).set_index([y_train.index.values])\n",
    "    test_yeo_X = pd.DataFrame(scalerX.transform(X_test), columns=X_test.columns.values).set_index([X_test.index.values])\n",
    "    test_yeo_y = pd.DataFrame(scalery.transform(y_test), columns=y_test.columns.values).set_index([y_test.index.values])\n",
    "    return scalerX, scalery, train_yeo_X, train_yeo_y, test_yeo_X, test_yeo_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_test, y_train, y_test):\n",
    "    scalerX = MinMaxScaler(copy=True, feature_range=(0,1)).fit(X_train)\n",
    "    scalery = MinMaxScaler(copy=True, feature_range=(0,1)).fit(y_train)\n",
    "    train_minmax_X = pd.DataFrame(scalerX.transform(X_train), columns=X_train.columns.values).set_index([X_train.index.values])\n",
    "    train_minmax_y = pd.DataFrame(scalery.transform(y_train), columns=y_train.columns.values).set_index([y_train.index.values])\n",
    "    test_minmax_X = pd.DataFrame(scalerX.transform(X_test), columns=X_test.columns.values).set_index([X_test.index.values])\n",
    "    test_minmax_y = pd.DataFrame(scalery.transform(y_test), columns=y_test.columns.values).set_index([y_test.index.values])\n",
    "    return scalerX, scalery, train_minmax_X, train_minmax_y, test_minmax_X, test_minmax_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IQR Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_robust_scaler(X_train, X_test, y_train, y_test):\n",
    "    scalerX = RobustScaler(quantile_range=(25.0,75.0), copy=True, with_centering=True, with_scaling=True).fit(X_train)\n",
    "    scalery = RobustScaler(quantile_range=(25.0,75.0), copy=True, with_centering=True, with_scaling=True).fit(y_train)\n",
    "    train_iqr_X = pd.DataFrame(scalerX.transform(X_train), columns=X_train.columns.values).set_index([X_train.index.values])\n",
    "    train_iqr_y = pd.DataFrame(scalery.transform(y_train), columns=y_train.columns.values).set_index([y_train.index.values])\n",
    "    test_iqr_X = pd.DataFrame(scalerX.transform(X_test), columns=X_test.columns.values).set_index([X_test.index.values])\n",
    "    test_iqr_y = pd.DataFrame(scalery.transform(y_test), columns=y_test.columns.values).set_index([y_test.index.values])\n",
    "    return scalerX, scalery, train_iqr_X, train_iqr_y, test_iqr_X, test_iqr_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
